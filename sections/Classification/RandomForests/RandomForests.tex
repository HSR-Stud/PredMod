\subsection{Random Forests}
	\subsubsection{Bootstrapping}
	 	\RTheory
	 	{
	 		Bootstrapping is used to estimate some arbitrary quantity $\gamma$
	 		
	 	    \textbf{Algorithm:}

			\begin{enumerate}
    	    	\item Choose a (large) number $B \in N$
    	    	\item For $b = 1,\dots,B$
    	    		\begin{enumerate}
    	    		    \item Draw $n$ samples $\left\{x_1^*,\dots,x_n^*\right\}$ from $\left\{x_1,\dots,x_n\right\}$ with replacement.
    	    		    \item Compute the estimator $\hat{\gamma} = \hat{\gamma}(x_1^*,\dots,x_n^*)$
    	    		\end{enumerate}
    	    	\item The empirical distribution $\hat{F}^*(\hat{\gamma}_1^*,\dots,\hat{\gamma}_n^*)$ approximates the distribution of $\hat{\gamma}$.
    		\end{enumerate}
    		
    		\textbf{Estimators:}
    		
    		$$\begin{aligned}
    			\bar{\gamma}^* &= \frac{1}{B} \sum\limits_{b=1}^B \hat{\gamma}_b^*\\
    			se_B(\hat{\gamma}) &= \sqrt{\frac{1}{B-1} \sum\limits_{b=1}^B (\hat{\gamma}_b^* - \bar{\gamma}^*)}
    		\end{aligned}$$
    	}
    	{
    		sections/Classification/RandomForests/Bootstrap/example.R
    	}	
    	
    \subsubsection{Bagging}
	 	\RTheory
	 	{
	 		The use of bootstrapping to generate $B$ models using bootstrapped training sets. The resulting bagged model is:
	 		
	 		\begin{itemize}
	 		    \item \textbf{For regression:}
	 		    
	 		    	$$ \hat{f}_{bag}(x) = \frac{1}{B} \sum\limits_{b=1}^B f_b^*(x)$$
	 		    	
	 		  	\item \textbf{For classification:}
	 		  	
					Typically the most commonly resulting class is used (\emph{majority vote}).
	 		  	
	 		  	\item \textbf{For decision trees:}
	 		  	
	 	    		Models are grown deep and left unpruned, then majority vote is applied. (See example \textrightarrow)
	 	    		
	 	    	\item \textbf{Out of bag error estimate:}
	 	    	
			 	    \begin{enumerate}
			 	        \item For $i = 1,\dots, n$ find all bootstrapped models $\hat{f}_b^*$ that do not use the $i$-th observation for training
			 	        \item The out-of-bag (OOB) error estimate is the classification error
			 	        	$$Err^* = \frac{1}{n} \sum\limits_{i=1}^nI(y_i \neq \hat{y}_i^*)$$ 
			 	    \end{enumerate}
	 		\end{itemize}
	 		
	 		
	 	    
	 	    
	 	    
	 	    
	 	    
	 	    
    	}
    	{
    		sections/Classification/RandomForests/Bagging/example.R
    	}		